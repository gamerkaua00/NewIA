<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IA Local - Projeto Neural</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/marked/12.0.0/marked.min.js"></script>
    
    <!-- Usando o 'esm.run' para pegar SEMPRE a vers√£o mais recente e compat√≠vel -->
    <script type="module">
        import * as webllm from "https://esm.run/@mlc-ai/web-llm";

        // CONFIGURA√á√ÉO DE MODELO (Upgrade de Intelig√™ncia)
        // Trocamos o 1B pelo 3B. √â um pouco mais pesado, mas MUITO mais inteligente.
        const selectedModel = "Llama-3.2-3B-Instruct-q4f16_1-MLC";

        let engine = null;
        let chatHistory = [];

        const $ = (id) => document.getElementById(id);

        async function initChat() {
            $('status-text').innerText = "Verificando compatibilidade WebGPU...";
            $('error-log').classList.add('hidden');
            $('loading-bar').style.width = "5%";
            
            const initProgressCallback = (report) => {
                $('status-text').innerText = report.text;
                // L√≥gica da barra de progresso
                if(report.text.includes("Fetching param cache")) {
                    const match = report.text.match(/(\d+)%/);
                    if (match) $('loading-bar').style.width = match[1] + "%";
                } else if (report.text.includes("Loading model")) {
                     $('loading-bar').style.width = "90%";
                } else if (report.text.includes("Finish")) {
                     $('loading-bar').style.width = "100%";
                }
            };

            try {
                // Verifica√ß√£o r√≠gida de suporte
                if (!navigator.gpu) {
                    throw new Error("Seu navegador n√£o suporta WebGPU. Use Chrome ou Edge (Desktop/Android) atualizados.");
                }

                console.log("Inicializando motor para:", selectedModel);

                // CRIA√á√ÉO DO MOTOR
                engine = await webllm.CreateMLCEngine(
                    selectedModel,
                    { 
                        initProgressCallback: initProgressCallback,
                        logLevel: "INFO" 
                    }
                );
                
                $('status-text').innerText = "C√©rebro Carregado!";
                $('loading-bar').style.width = "100%";
                
                setTimeout(() => $('loading-container').style.display = 'none', 800);
                $('send-btn').disabled = false;
                
                // Prompt do Sistema MELHORADO (Menos rob√¥, mais conversa)
                const systemPrompt = `
Voc√™ √© uma assistente virtual inteligente e prestativa rodando diretamente no navegador do usu√°rio.
- Responda de forma natural, fluida e amig√°vel.
- Mantenha o idioma sempre em Portugu√™s do Brasil.
- Se o usu√°rio disser "Oi", cumprimente de volta e pergunte como pode ajudar.

COMANDOS INTERNOS (Use apenas quando necess√°rio):
- [BUSCAR: termo] -> Use para solicitar pesquisa na web quando n√£o souber algo atual.
- [SALVAR: dados] -> Use para solicitar salvamento de mem√≥ria importante.
`;
                chatHistory.push({ role: "system", content: systemPrompt });

            } catch (err) {
                $('loading-container').style.display = 'flex';
                $('status-text').innerText = "Erro na inicializa√ß√£o.";
                
                $('error-log').innerHTML = `
                    <div class="font-bold text-red-300">Erro T√©cnico:</div>
                    <div class="mb-2">${err.message}</div>
                    <div class="text-xs text-gray-400 border-t border-gray-600 pt-2 mt-2">
                        Se o download travou anteriormente, os arquivos podem estar corrompidos.
                    </div>
                    <button onclick="window.clearCache()" class="mt-3 w-full bg-red-600 hover:bg-red-700 text-white py-2 rounded text-xs uppercase font-bold transition-colors">
                        For√ßar Limpeza de Cache
                    </button>
                `;
                $('error-log').classList.remove('hidden');
                console.error("Erro detalhado:", err);
            }
        }

        window.clearCache = async () => {
             if(confirm("Isso apagar√° todos os arquivos da IA baixados e tentar√° baixar novamente do zero. Continuar?")) {
                try {
                    $('status-text').innerText = "Limpando cache...";
                    const cacheKeys = await caches.keys();
                    for (const key of cacheKeys) {
                        if (key.includes("webllm")) await caches.delete(key);
                    }
                    
                    const databases = await window.indexedDB.databases();
                    for (const db of databases) {
                        if (db.name && db.name.includes("webllm")) {
                            window.indexedDB.deleteDatabase(db.name);
                        }
                    }
                    localStorage.clear();
                    alert("Cache limpo com sucesso. A p√°gina ser√° recarregada.");
                    window.location.reload();
                } catch (e) {
                    alert("Erro ao limpar: " + e.message);
                }
             }
        }

        function appendMessage(role, text, id = null) {
            const chatBox = $('chat-box');
            let div = id ? document.getElementById(id) : null;
            
            if (!div) {
                div = document.createElement('div');
                if (id) div.id = id;
                div.className = `p-3 rounded-lg max-w-[85%] mb-2 text-sm leading-relaxed shadow-sm animate-fade-in ${
                    role === 'user' 
                    ? 'bg-blue-600 text-white self-end ml-auto rounded-tr-none' 
                    : 'bg-gray-700 text-gray-200 self-start rounded-tl-none prose prose-invert max-w-none'
                }`;
                chatBox.appendChild(div);
            }

            // Usando 'marked' para renderizar Markdown bonitinho (negrito, listas, etc)
            if (role === 'assistant') {
                div.innerHTML = marked.parse(text);
            } else {
                div.innerText = text;
            }
            
            chatBox.scrollTop = chatBox.scrollHeight;
            return div;
        }

        window.sendMessage = async () => {
            const input = $('user-input');
            const text = input.value.trim();
            if (!text || !engine) return;

            appendMessage('user', text);
            input.value = '';
            chatHistory.push({ role: "user", content: text });

            // ID √∫nico para a mensagem que vai ser gerada (para streaming)
            const responseId = 'msg-' + Date.now();
            
            // Cria container vazio para a resposta
            appendMessage('assistant', '<span class="animate-pulse">Pensando...</span>', responseId);

            try {
                // STREAMING: Aqui est√° o segredo da velocidade percebida
                const chunks = await engine.chat.completions.create({
                    messages: chatHistory,
                    temperature: 0.7,
                    max_tokens: 2048,
                    stream: true // Ativa o modo fluxo
                });

                let fullResponse = "";
                let buffer = "";

                // Loop que atualiza a tela a cada pedacinho de texto que a IA gera
                for await (const chunk of chunks) {
                    const content = chunk.choices[0]?.delta?.content || "";
                    fullResponse += content;
                    
                    // Detec√ß√£o de comandos em tempo real
                    if (fullResponse.includes("[BUSCAR:") || fullResponse.includes("[SALVAR:")) {
                        buffer = fullResponse; // Segura para n√£o mostrar o comando cru
                    } else {
                        // Atualiza a tela instantaneamente
                        appendMessage('assistant', fullResponse, responseId);
                    }
                }

                // Verifica se houve comando ao final
                if (fullResponse.includes("[BUSCAR:")) {
                     document.getElementById(responseId).remove(); // Remove o texto cru
                     handleSearchTool(fullResponse);
                } else if (fullResponse.includes("[SALVAR:")) {
                     document.getElementById(responseId).remove();
                     handleSaveTool(fullResponse);
                } else {
                    chatHistory.push({ role: "assistant", content: fullResponse });
                }

            } catch (err) {
                appendMessage('assistant', "Erro na gera√ß√£o: " + err.message);
            }
        };

        // --- Ferramentas Simuladas (Por enquanto) ---

        async function handleSearchTool(command) {
            const query = command.match(/\[BUSCAR: (.*?)\]/)[1];
            appendMessage('assistant', `üîé <i>Pesquisando: "${query}"...</i>`);
            
            setTimeout(async () => {
                const fakeResult = `Resultado simulado para "${query}": Em breve, conectaremos isso ao Google Search API gratuito.`;
                chatHistory.push({ role: "system", content: `[SISTEMA]: Resultado da busca: "${fakeResult}".` });
                
                // Gera resposta final com base na "busca"
                const followUp = await engine.chat.completions.create({ messages: chatHistory });
                const finalText = followUp.choices[0].message.content;
                appendMessage('assistant', finalText);
                chatHistory.push({ role: "assistant", content: finalText });
            }, 1000);
        }

        async function handleSaveTool(command) {
            const data = command.match(/\[SALVAR: (.*?)\]/)[1];
            
            const savedItems = JSON.parse(localStorage.getItem('ia_memoria') || '[]');
            savedItems.push({ data: new Date().toISOString(), content: data });
            localStorage.setItem('ia_memoria', JSON.stringify(savedItems));

            appendMessage('assistant', `üíæ <i>Mem√≥ria salva: "${data}"</i>`);
            chatHistory.push({ role: "assistant", content: `Salvei: ${data}` });
        }

        $('user-input').addEventListener('keypress', (e) => {
            if (e.key === 'Enter') window.sendMessage();
        });

        window.onload = initChat;
    </script>
    <style>
        @keyframes fade-in { from { opacity: 0; transform: translateY(5px); } to { opacity: 1; transform: translateY(0); } }
        .animate-fade-in { animation: fade-in 0.3s ease-out; }
        /* Estilos para markdown */
        .prose p { margin-bottom: 0.5em; }
        .prose ul { list-style-type: disc; padding-left: 1.5em; margin-bottom: 0.5em; }
        .prose strong { color: #fff; font-weight: bold; }
    </style>
</head>
<body class="bg-gray-900 text-gray-100 h-screen flex flex-col font-sans overflow-hidden">

    <!-- Header -->
    <header class="bg-gray-800 p-4 border-b border-gray-700 flex justify-between items-center shadow-lg z-10">
        <div class="flex items-center gap-3">
            <div class="relative">
                <div class="w-3 h-3 rounded-full bg-blue-500 animate-pulse"></div>
                <div class="absolute inset-0 w-3 h-3 rounded-full bg-blue-500 blur-sm animate-pulse"></div>
            </div>
            <div>
                <h1 class="font-bold text-lg tracking-wide leading-none">Projeto Neural</h1>
                <span class="text-[10px] text-gray-400 font-mono">CORE: LLAMA 3.2 3B (Inteligente)</span>
            </div>
        </div>
        
        <div class="flex gap-2 text-xs">
            <div class="px-2 py-1 bg-gray-700 rounded border border-gray-600 flex items-center gap-2">
                WebGPU
                <span class="w-2 h-2 rounded-full bg-green-500"></span>
            </div>
        </div>
    </header>

    <!-- Overlay de Carregamento -->
    <div id="loading-container" class="absolute inset-0 bg-gray-900 z-50 flex flex-col items-center justify-center p-6 text-center backdrop-blur-sm">
        <div class="w-full max-w-md bg-gray-800 rounded-xl p-8 shadow-2xl border border-gray-700 relative overflow-hidden">
            <!-- Glow effect -->
            <div class="absolute top-0 left-0 w-full h-1 bg-gradient-to-r from-blue-500 via-purple-500 to-blue-500"></div>

            <h2 class="text-xl font-bold mb-4 text-white">Carregando C√©rebro Digital</h2>
            
            <div class="w-full bg-gray-900 h-4 rounded-full overflow-hidden mb-2 border border-gray-600">
                <div id="loading-bar" class="h-full bg-blue-600 transition-all duration-300 relative" style="width: 0%">
                    <div class="absolute inset-0 bg-white/20 animate-[pulse_2s_infinite]"></div>
                </div>
            </div>
            
            <p id="status-text" class="text-blue-300 text-sm font-mono mt-2 min-h-[20px]">Inicializando...</p>
            
            <div id="error-log" class="hidden mt-4 p-4 bg-red-900/30 border border-red-500/50 rounded text-red-200 text-left overflow-auto max-h-64"></div>

            <p class="text-xs text-gray-500 mt-6 border-t border-gray-700 pt-4">
                ‚ö†Ô∏è Baixando ~1.7GB (Llama 3.2 3B). <br>
                Este modelo √© mais inteligente que o anterior. <br>
                <span class="text-gray-600 italic">Necess√°rio apenas na primeira vez.</span>
            </p>
        </div>
    </div>

    <!-- √Årea do Chat -->
    <main class="flex-1 overflow-y-auto p-4 space-y-4 scroll-smooth bg-gradient-to-b from-gray-900 to-gray-800" id="chat-box">
        <div class="p-4 rounded-xl bg-gray-800/80 backdrop-blur border border-gray-700 text-gray-200 self-start max-w-[85%] shadow-lg">
            <p class="mb-2">‚ö° <b>Sistema Pronto (v2.0).</b></p>
            <p class="text-sm opacity-80">
                Atualizei meu n√∫cleo para o Llama 3.2 3B. Estou mais esperta e responderei em tempo real (streaming).
            </p>
        </div>
    </main>

    <!-- Input -->
    <footer class="bg-gray-800 p-4 border-t border-gray-700 z-10">
        <div class="max-w-4xl mx-auto flex gap-3 relative">
            <input type="text" id="user-input" 
                class="w-full bg-gray-900 border border-gray-600 rounded-xl px-5 py-3 text-white placeholder-gray-500 focus:outline-none focus:border-blue-500 focus:ring-1 focus:ring-blue-500 transition-all shadow-inner"
                placeholder="Digite sua mensagem..." autocomplete="off">
                
            <button onclick="window.sendMessage()" id="send-btn" disabled
                class="bg-blue-600 hover:bg-blue-500 disabled:bg-gray-700 disabled:text-gray-500 disabled:cursor-not-allowed text-white px-6 rounded-xl font-bold transition-all shadow-lg hover:shadow-blue-500/20 active:scale-95 flex items-center justify-center min-w-[60px]">
                <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M15.854.146a.5.5 0 0 1 .11.54l-5.819 14.547a.75.75 0 0 1-1.329.124l-3.178-4.995L.643 7.184a.75.75 0 0 1 .124-1.33L15.314.037a.5.5 0 0 1 .54.11ZM6.636 10.07l2.761 4.338L14.13 2.576 6.636 10.07Zm6.787-8.201L1.591 6.602l4.339 2.76 7.494-7.493Z"/>
                </svg>
            </button>
        </div>
    </footer>

</body>
</html>
